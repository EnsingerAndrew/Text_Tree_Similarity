{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toy Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.0027\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "# Reference (ground truth) and candidate (generated) sentences\n",
    "\n",
    "string1 = '''\"Foods\": {\n",
    "        \"Proteins\": {\n",
    "            \"Meat\": \"A rich source of protein, meat includes options like chicken, beef, pork, and lamb, each offering essential nutrients.\",\n",
    "            \"Seafood\": \"Fish and shellfish, such as salmon, tuna, shrimp, and cod, provide high-quality protein and omega-3 fatty acids.\",\n",
    "            \"Dairy\": \"Dairy products like milk, cheese, yogurt, and butter offer calcium, protein, and probiotics for digestive health.\",\n",
    "            \"Plant-Based\": \"Foods like tofu, tempeh, lentils, and chickpeas serve as excellent meat alternatives with high protein and fiber content.\"\n",
    "        },\n",
    "        \"Fruits & Vegetables\": {\n",
    "            \"Fruits\": \"Nutrient-dense and naturally sweet, fruits like apples, bananas, oranges, and grapes provide vitamins, fiber, and antioxidants.\",\n",
    "            \"Berries\": \"Small but packed with nutrients, berries such as strawberries, blueberries, raspberries, and blackberries are rich in antioxidants.\",\n",
    "            \"Leafy Greens\": \"Vegetables like spinach, kale, lettuce, and arugula are loaded with vitamins, minerals, and fiber while being low in calories.\",\n",
    "            \"Root Vegetables\": \"Underground vegetables such as carrots, potatoes, beets, and radishes provide essential carbohydrates and vitamins.\"\n",
    "        },\n",
    "        \"Grains & Legumes\": {\n",
    "            \"Grains\": \"Staples like rice, wheat, oats, and quinoa are excellent sources of energy and essential carbohydrates.\",\n",
    "            \"Pasta & Breads\": \"Whole wheat, white, multigrain, and sourdough options provide important fiber and carbohydrates for a balanced diet.\",\n",
    "            \"Beans\": \"Black beans, kidney beans, pinto beans, and navy beans are protein-rich legumes packed with fiber and minerals.\",\n",
    "            \"Lentils\": \"Red, green, brown, and black lentils are versatile and nutritious, offering high protein and iron content.\"\n",
    "        },\n",
    "        \"Fats & Oils\": {\n",
    "            \"Cooking Oils\": \"Oils like olive, coconut, avocado, and vegetable are used in cooking and contain essential fatty acids.\",\n",
    "            \"Animal Fats\": \"Butter, lard, ghee, and tallow are traditional cooking fats that add flavor and richness to dishes.\",\n",
    "            \"Nut & Seed Oils\": \"Sesame, flaxseed, sunflower, and walnut oils provide unique flavors and are often used in dressings and cooking.\",\n",
    "            \"Dairy-Based Fats\": \"Cream, clarified butter, cheese fat, and yogurt fat add richness and texture to various foods.\"\n",
    "        },\n",
    "        \"Beverages & Sweeteners\": {\n",
    "            \"Water\": \"Essential for hydration, water comes in various forms, including still, sparkling, mineral, and flavored options.\",\n",
    "            \"Tea & Coffee\": \"Popular beverages like black tea, green tea, espresso, and lattes provide caffeine and antioxidants.\",\n",
    "            \"Juices & Sodas\": \"Drinks such as orange juice, apple juice, cola, and lemonade offer sweetness but can vary in nutritional value.\",\n",
    "            \"Sweeteners\": \"Sugar, honey, maple syrup, and stevia are commonly used to enhance flavor in foods and beverages.\"\n",
    "        }\n",
    "    },'''\n",
    "\n",
    "string2 = '''\"Countries\": {\n",
    "        \"United States\": {\n",
    "            \"New York City\": \"A dynamic urban center renowned for its iconic landmarks, including Times Square, Broadway theaters, and the Statue of Liberty.\",\n",
    "            \"Los Angeles\": \"A hub of the entertainment industry, featuring Hollywood, picturesque beaches, and a lively cultural scene.\",\n",
    "            \"Chicago\": \"Recognized for its signature deep-dish pizza, striking skyline, and the renowned Willis Tower.\",\n",
    "            \"San Francisco\": \"Famous for the Golden Gate Bridge, historic Alcatraz Island, and its distinctive hilly streets.\"\n",
    "        },\n",
    "        \"France\": {\n",
    "            \"Paris\": \"The City of Light, celebrated for the Eiffel Tower, world-class museums like the Louvre, and its influence in fashion.\",\n",
    "            \"Marseille\": \"A vibrant port city distinguished by its seafood cuisine, historic harbor, and multicultural heritage.\",\n",
    "            \"Lyon\": \"A gastronomic capital known for its culinary excellence, Roman-era sites, and historic silk trade.\",\n",
    "            \"Nice\": \"A breathtaking coastal destination along the French Riviera, admired for its beaches and Mediterranean allure.\"\n",
    "        },\n",
    "        \"Japan\": {\n",
    "            \"Tokyo\": \"A dynamic metropolis blending ancient traditions with cutting-edge technology, featuring lively districts and historic temples.\",\n",
    "            \"Kyoto\": \"A city steeped in history, known for its timeless shrines, scenic bamboo groves, and traditional geisha culture.\",\n",
    "            \"Osaka\": \"A bustling city famed for its vibrant street food scene, historic Osaka Castle, and energetic nightlife.\",\n",
    "            \"Hiroshima\": \"A place of remembrance and resilience, home to the Peace Memorial Park and a rich historical legacy.\"\n",
    "        },\n",
    "        \"Italy\": {\n",
    "            \"Rome\": \"A city brimming with history, featuring ancient wonders such as the Colosseum and the grandeur of Vatican City.\",\n",
    "            \"Milan\": \"A global epicenter of fashion and design, known for its elegant streets, renowned art, and architectural marvels.\",\n",
    "            \"Venice\": \"A one-of-a-kind city built on waterways, famous for its scenic gondola rides and the charm of St. Mark's Square.\",\n",
    "            \"Florence\": \"The birthplace of the Renaissance, celebrated for its stunning Duomo, Michelangelo's David, and world-class museums.\"\n",
    "        },\n",
    "        \"Brazil\": {\n",
    "            \"Rio de Janeiro\": \"A city known for its stunning landscapes, featuring Christ the Redeemer, the lively Carnival, and iconic beaches like Copacabana.\",\n",
    "            \"Sao Paulo\": \"Brazil's economic powerhouse, distinguished by its soaring skyscrapers, diverse culinary scene, and rich cultural offerings.\",\n",
    "            \"Salvador\": \"A city bursting with Afro-Brazilian heritage, colonial-era architecture, and a thriving music and dance culture.\",\n",
    "            \"Brasilia\": \"The capital city, recognized for its futuristic urban planning, modernist architecture, and political importance.\"\n",
    "        }\n",
    "    },'''\n",
    "\n",
    "reference = [string1]\n",
    "candidate = string2\n",
    "\n",
    "# Tokenize sentences\n",
    "reference_tokens = [reference[0].split()]  # NLTK expects a list of lists\n",
    "candidate_tokens = candidate.split()\n",
    "\n",
    "# Compute BLEU score with smoothing to avoid zero scores for short sentences\n",
    "smoothing = SmoothingFunction().method1\n",
    "bleu_score = sentence_bleu(reference_tokens, candidate_tokens, smoothing_function=smoothing)\n",
    "\n",
    "print(f\"BLEU Score: {bleu_score:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First child of root: Child1\n",
      "Second child of child2: Child5\n",
      "Root\n",
      "├── Child1\n",
      "├── Child2\n",
      "│   ├── Child4\n",
      "│   └── Child5\n",
      "└── Child3\n"
     ]
    }
   ],
   "source": [
    "from anytree import Node, RenderTree\n",
    "\n",
    "# Create nodes with string data\n",
    "root = Node(\"Root\")\n",
    "child1 = Node(\"Child1\", parent=root)\n",
    "child2 = Node(\"Child2\", parent=root)\n",
    "child3 = Node(\"Child3\", parent=root)\n",
    "\n",
    "# Add children to a specific node\n",
    "child4 = Node(\"Child4\", parent=child2)\n",
    "child5 = Node(\"Child5\", parent=child2)\n",
    "\n",
    "# Access children via indexing\n",
    "print(\"First child of root:\", root.children[0].name)  # Accessing first child\n",
    "print(\"Second child of child2:\", child2.children[1].name)  # Accessing second child of child2\n",
    "\n",
    "# Print the tree structure\n",
    "for pre, fill, node in RenderTree(root):\n",
    "    print(f\"{pre}{node.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "import torch\n",
    "\n",
    "# Load the Universal Sentence Encoder model\n",
    "model_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "model = hub.load(model_url)\n",
    "\n",
    "# Sentence to embed\n",
    "sentence = \"Google's Universal Sentence Encoder generates 512-dimensional embeddings.\"\n",
    "\n",
    "# Generate the embedding\n",
    "embedding = model([sentence])[0].numpy()\n",
    "embedding = torch.tensor(embedding)\n",
    "print(embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(str, model): \n",
    "    embedding = model([str])[0].numpy()\n",
    "    return torch.tensor(embedding)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "model_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "model = hub.load(model_url)\n",
    "\n",
    "sentence = \"Google's Universal Sentence Encoder generates 512-dimensional embeddings.\"\n",
    "emb = embed(sentence, model)\n",
    "print(emb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading Json Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Foods', 'Countries', 'Leaders', 'Lifestyle', 'Products'])\n",
      "\t dict_keys(['Proteins', 'Fruits & Vegetables', 'Grains & Legumes', 'Fats & Oils', 'Beverages & Sweeteners'])\n",
      "\t dict_keys(['France', 'United States', 'Japan', 'Italy', 'Brazil'])\n",
      "\t dict_keys(['United States', 'France', 'Japan', 'Italy', 'Brazil'])\n",
      "dict_keys(['Foods', 'Countries', 'Leaders', 'Lifestyle', 'Products'])\n",
      "\t dict_keys(['Protein Sources', 'Grains & Legumes', 'Fats & Oils', 'Beverages & Drinks '])\n",
      "\t dict_keys(['United States', 'France', 'Japan', 'Italy', 'Brazil'])\n",
      "\t dict_keys(['United States', 'France', 'Japan', 'Italy', 'Brazil'])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def read_json(file_path):\n",
    "    with open(file_path, 'r') as file: data = json.load(file)\n",
    "    return data\n",
    "\n",
    "collection = read_json(\"origin.json\")\n",
    "print(collection.keys())\n",
    "Foods = collection[\"Foods\"]\n",
    "Countries = collection[\"Countries\"]\n",
    "Leaders = collection[\"Leaders\"]\n",
    "print(\"\\t\",Foods.keys())\n",
    "print(\"\\t\",Countries.keys())\n",
    "print(\"\\t\",Leaders.keys())\n",
    "\n",
    "collection = read_json(\"positives.json\")\n",
    "print(collection.keys())\n",
    "Foods2 = collection[\"Foods\"]\n",
    "Countries2= collection[\"Countries\"]\n",
    "Leaders2 = collection[\"Leaders\"]\n",
    "print(\"\\t\",Foods2.keys())\n",
    "print(\"\\t\",Countries2.keys())\n",
    "print(\"\\t\",Leaders2.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json2tree(input, model): # TREE MUST HAVE ONLY 2 LAYERS \n",
    "    root = Node(\"Root\")\n",
    "    for K1 in input.keys(): \n",
    "        child1 = Node(K1, parent=root)\n",
    "        for K2 in input[K1].keys(): \n",
    "            child2 = Node(K2, parent=child1)\n",
    "            desc = Node(input[K1][K2], parent=child2)\n",
    "    \n",
    "    for pre, fill, node in RenderTree(root): node.vect = torch.tensor(model([node.name])[0].numpy())\n",
    "    return root\n",
    "\n",
    "def tree_print(tree): \n",
    "    for pre, fill, node in RenderTree(tree):\n",
    "        print(f\"{pre}{node.name}:{node.vect.shape}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "mym = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Score Function + Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "len(L2_collection): 20\n",
      "len(L2_alignments): 20\n",
      "len(L2_topis): 20\n",
      "\n",
      "len(L3_collection): 20\n",
      "len(L3_alignments): 20\n",
      "len(L3_topis): 20\n",
      "\n",
      "Layer Alignments: tensor(0.5692) tensor(0.5836) tensor(0.5274)\n",
      "\n",
      "Alignment Score / Topis Score / Diff Score: 0.5600563883781433 0.3851846423379939 0.620572396891393\n",
      "tensor(0.1143, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andre\\AppData\\Local\\Temp\\ipykernel_12148\\1818982247.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  L1_diffs = torch.sigmoid(torch.norm(torch.tensor(L1_topis).to(float)))\n",
      "C:\\Users\\Andre\\AppData\\Local\\Temp\\ipykernel_12148\\1818982247.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  L2_diffs = torch.sigmoid(torch.norm(torch.tensor(L2_topis).to(float)))\n",
      "C:\\Users\\Andre\\AppData\\Local\\Temp\\ipykernel_12148\\1818982247.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  L3_diffs = torch.sigmoid(torch.norm(torch.tensor(L3_topis).to(float)))\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def tree_align(tree_a, tree_b): \n",
    "    al1 = tree_a.children\n",
    "    al2 = tree_b.children\n",
    "\n",
    "    outer_tree, inner_tree = list(al1), list(al2)\n",
    "    if(len(al1) > len(al2)): outer_tree, inner_tree = list(al2), list(al1)\n",
    "    diff = abs(len(al1) - len(al2))\n",
    "\n",
    "    topis = []\n",
    "    alignments = []\n",
    "    pairs = []\n",
    "    for i in range(len(outer_tree)): \n",
    "        vector = outer_tree[i].vect\n",
    "        correlations = torch.zeros(len(inner_tree))\n",
    "\n",
    "        for j in range(len(inner_tree)): \n",
    "            correlations[j] = torch.inner(vector, inner_tree[j].vect)\n",
    "        \n",
    "        topi = torch.argmax(correlations)\n",
    "        alignments.append(correlations[topi])\n",
    "        topis.append(topi)\n",
    "        pairs.append((outer_tree[i], inner_tree[topi]))\n",
    "        inner_tree.pop(topi)\n",
    "\n",
    "    return pairs, alignments, topis, diff\n",
    "\n",
    "def activate(num): return (num + 1)/2\n",
    "\n",
    "def layer_alignment(alignments): \n",
    "    nums = [activate(elem.item()) for elem in alignments]\n",
    "    return torch.mean(torch.tensor(nums))\n",
    "\n",
    "def score(a, b, model):\n",
    "    alpha = 3 \n",
    "    beta = 0.3\n",
    "    gamma = 0.3\n",
    "\n",
    "\n",
    "    # CONVERTING JSON DICTIONARY TO TREES\n",
    "    tree_a = json2tree(a,model)\n",
    "    tree_b = json2tree(b,model)\n",
    "\n",
    "    # LAYER 1 ALIGNMENTS\n",
    "    L1_collection, L1_alignments, L1_topis, L1_diffs = tree_align(tree_a, tree_b)\n",
    "    L1_diffs = [L1_diffs]\n",
    "\n",
    "    # LAYER 2 ALIGNMENTS\n",
    "    L2_collection, L2_alignments, L2_topis, L2_diffs = [], [], [], []\n",
    "    for pair in L1_collection: \n",
    "        L2_pairs, L2a, L2t, L2d = tree_align(pair[0], pair[1])\n",
    "        L2_collection.extend(L2_pairs)\n",
    "        L2_alignments.extend(L2a)\n",
    "        L2_topis.extend(L2t)\n",
    "        L2_diffs.extend([L2d])\n",
    "\n",
    "    print(\"\\nlen(L2_collection):\",len(L2_collection))    \n",
    "    print(\"len(L2_alignments):\",len(L2_alignments))\n",
    "    print(\"len(L2_topis):\",len(L2_topis))\n",
    "\n",
    "    # LAYER 3 ALIGNMENTS\n",
    "    L3_collection, L3_alignments, L3_topis, L3_diffs = [], [], [], []\n",
    "    for pair in L2_collection: \n",
    "        L3_pairs, L3a, L3t, L3d = tree_align(pair[0], pair[1])\n",
    "        L3_collection.extend(L3_pairs)\n",
    "        L3_alignments.extend(L3a)\n",
    "        L3_topis.extend(L3t)\n",
    "        L3_diffs.extend([L3d])\n",
    "\n",
    "    print(\"\\nlen(L3_collection):\",len(L3_collection))    \n",
    "    print(\"len(L3_alignments):\",len(L3_alignments))\n",
    "    print(\"len(L3_topis):\",len(L3_topis))\n",
    "\n",
    "    # LAYER ALIGNMENT SCORE PROCESSING\n",
    "    L1A = layer_alignment(L1_alignments)\n",
    "    L2A = layer_alignment(L2_alignments)\n",
    "    L3A = layer_alignment(L3_alignments)\n",
    "    alignment_score = (L1A + L2A + L3A)/3\n",
    "    print(\"\\nLayer Alignments:\", L1A, L2A, L3A)\n",
    "\n",
    "    # LAYER TOPIS SCORE PROCESSING\n",
    "    L1_topis = torch.sigmoid(torch.norm(torch.tensor(L1_topis).to(float)))\n",
    "    L2_topis = torch.sigmoid(torch.norm(torch.tensor(L2_topis).to(float)))\n",
    "    L3_topis = torch.sigmoid(torch.norm(torch.tensor(L3_topis).to(float)))\n",
    "    topis_score = -2*((L1_topis + L2_topis + L3_topis)/3)+2\n",
    "\n",
    "    # LAYER DIFFERENCES SCORE PROCESSING\n",
    "    L1_diffs = torch.sigmoid(torch.norm(torch.tensor(L1_topis).to(float)))\n",
    "    L2_diffs = torch.sigmoid(torch.norm(torch.tensor(L2_topis).to(float)))\n",
    "    L3_diffs = torch.sigmoid(torch.norm(torch.tensor(L3_topis).to(float)))\n",
    "    diff_score = -2*((L1_diffs + L2_diffs + L3_diffs)/3)+2\n",
    " \n",
    "    print(\"\\nAlignment Score / Topis Score / Diff Score:\", alignment_score.item(), topis_score.item(), diff_score.item())\n",
    "\n",
    "    return (alignment_score**alpha) * (topis_score**beta) * (diff_score**gamma)\n",
    "\n",
    "print(score(Foods, Countries, mym))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
